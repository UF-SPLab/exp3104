<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Perceiving Objects and Scenes</title>
    <meta charset="utf-8" />
    <meta name="author" content="Sensory Processes – EXP3104" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link rel="stylesheet" href="libs/myassets/remark-css/hygge.css" type="text/css" />
    <link rel="stylesheet" href="https://afeld.github.io/emoji-css/emoji.css" type="text/css" />
    <link rel="stylesheet" href="libs/myassets/remark-css/header-footer.css" type="text/css" />
    <link rel="stylesheet" href="libs/myassets/remark-css/griddage.css" type="text/css" />
    <link rel="stylesheet" href="libs/myassets/remark-css/grid-some.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Perceiving Objects and Scenes
## Chapter 5
### Sensory Processes – EXP3104

---

class: inverse, center, middle




# Why Is It So Difficult to Design a Perceiving Machine?

### Discuss reasons why object perception is challenging.


---

# .font70[Why Is It So Difficult to Design a Perceiving Machine?]

**Inverse projection problem**: image on retina caused by infinite number of objects.
- .font90[Proximal stimulus on &lt;/br&gt; receptors is ambiguous.]
- .font90[**Occlusions** are common &lt;/br&gt; in the environment.]
- .font90[Objects can be hidden &lt;/br&gt;  or blurred.]
    

![:positionImage 55%, 0%, 0deg, 450px](michael-murphy-04.jpg)
![:positionImage 55%, 50%, 0deg, 450px](michael-murphy-05.jpg)
![:positionImage 22%, 33%, 0deg, 600px](fig_5_5.png)

---
# .font70[Why Is It So Difficult to Design a Perceiving Machine?]

![:positionImage 15%, 5%, 0deg, 350px](michael-murphy-02.jpg)

![:positionImage 20%, 55%, 0deg, 250px](off1.png)

![:positionImage 63%, 12%, 0deg, 250px](off-1.png)


![:positionImage 54%, 52%, 0deg, 400px](michael-murphy-01.jpg)
---
# .font70[Why Is It So Difficult to Design a Perceiving Machine?]

![:positionImage 15%, 5%, 0deg, 350px](michael-murphy-02.jpg)

![:positionImage 20%, 55%, 0deg, 250px](michael-murphy.gif)

![:positionImage 63%, 12%, 0deg, 250px](off-1.png)


![:positionImage 54%, 52%, 0deg, 400px](michael-murphy-01.jpg)


---
background-image: url(michael-murphy-01.jpg)
background-size: 100%
class: clear


---

# .font70[Why Is It So Difficult to Design a Perceiving Machine?]

- Humans are remarkably good at perceiving blurred, dim, distorted, incomplete, masked, obstructed, occluded, overlapped, rotated, skewed, wavy or unusual stimuli.  

![:positionImage 24%, 5%, 0deg, 350px](masked_face.jpg)

![:positionImage 24%, 45%, 0deg, 400px](captcha_methods.png)
--

![:positionImage 65%, 5%, 0deg, 350px](robot_tests.png)

![:positionImage 70%, 50%, 0deg, 300px](light.png)


---

# .font70[Why Is It So Difficult to Design a Perceiving Machine?]

Can you find these objects?  hidden pencil (*easy*) &amp; author’s glasses (*hard*)? 


![:positionImage 20%, 10%, 0deg, 700px](fig_5_7.png)

???

Figure 5.7 A portion of the mess on the author’s desk. Can you locate the hidden pencil (easy) and the author’s glasses (hard)? 



---

# .font70[Why Is It So Difficult to Design a Perceiving Machine?]

![](fig_5_8.png)

???

Figure 5.8 Who are these people? See page 121 for the answers. 


---

# .font70[Why Is It So Difficult to Design a Perceiving Machine?]
- Objects look different from different viewpoints.
    - **Viewpoint invariance**: the ability to recognize an object regardless of the viewpoint
    - This is a difficult task for computers to perform.


![](fig_5_9.png)

???

Figure 5.9 Your ability to recognize each of these views as being of the same chair is an example of viewpoint invariance.

---
class: inverse, center, middle

# Perceptual Organization

###	Discuss Gestalt psychology and the laws of perceptual organization.
###	Explain figure-ground segregation and identify the properties of figure-ground, gist of a scene.
### Describe the “oblique effect” and the “light-from-above” assumption, and discuss how these exemplifies the relationship between environmental regularities, physiology, and perception.

---

# Perceptual Organization

.pull-left[
### **Structuralism**
- Perceptions are created by *combining elements* called sensations
- Approach established by Wundt 
   - (late 1800s)
- Structuralism could not explain apparent movement.
]
.pull-right[
### **Gestalt Psychology**     
   translated: *composition* or *configuration* 
  
- **Perception** is **NOT** built up from sensations, but is a result of perceptual organization.  
-  **Gestalt psychology** in the 1920s by Wertheimer, Koffka, and Kohler
&gt; "The *whole* differs from the *sum* of its parts."

]

---

# Perceptual Organization

![](fig_5_10.png)

???

Figure 5.10 Examples of grouping and segregation in a city scene.


---
# .font70[The Gestalt Approach to Perceptual Grouping]  
.pull-left[### **Structuralism**   
Distinguished: sensations &amp; perceptions
many sensations *combined* = perception
]
.pull-right[### **Gestalt Psychology** 
**Apparent movement**&lt;span&gt;&amp;#8212;&lt;/span&gt;Illusion of movement  
**Illusory contours**&lt;span&gt;&amp;#8212;&lt;/span&gt;Appear real but have physical edge
]

![:positionImage 40%, 5%, 0deg, 350px](fig_5_12.png) 
![:positionImage 53%, 50%, 0deg, 440px](fig_5_11.png)




???

Figure 5.12 According to structuralism, a number of sensations (represented by the dots) add up to create our perception of the face.


Figure 5.11 Some black and white shapes that become perceptually organized into a Dalmatian. See page 121 for an outline of the Dalmatian.

---
# .font70[The Gestalt Approach to Perceptual Grouping]  
.pull-left[### **Structuralism**   
Distinguished: sensations &amp; perceptions
many sensations *combined* = perception
]
.pull-right[### **Gestalt Psychology** 
**Apparent movement**&lt;span&gt;&amp;#8212;&lt;/span&gt;Illusion of movement  
**Illusory contours**&lt;span&gt;&amp;#8212;&lt;/span&gt;Appear real but have physical edge
]

![:positionImage 40%, 5%, 0deg, 350px](fig_5_12.png) 

![:positionImage 53%, 50%, 0deg, 440px](rundog.gif)

???
Black &amp; white shapes become **perceptually organized** to a moving Dalmatian (Chapt 8)

---

# .font70[The Gestalt Approach to Perceptual Grouping]

.pull-left[
.img-w60[
![](fig_5_13.png)
]
]


.pull-right[
![](stranger.gif)
]

???

Figure 5.13 The conditions for creating apparent movement.  (a) One light flashes, followed by (b) a short period of darkness,  followed by (c) another light flashing in a different position. The  resulting perception, symbolized in (d), is a light moving from left to  right. Movement is seen between the two lights even though there  is only darkness in the space between them. 




---

# .font70[The Gestalt Approach to Perceptual Grouping]

.pull-left[
  
![](fig_5_15.png)

]



.pull-right[

![](kani.png)
  
]

???

Figure 5.15 The illusory contours clearly visible in (b) and (c) cannot be caused by sensations, because there is only white there.

---

![](kani_control.jpg)

---

# Gestalt Principles 

- **Good continuation**: connected points resulting in *straight or smooth* curves belong together (Lines are seen as following the smoothest path)



- **Pragnanz**: (conciseness, simplicity, good form) every stimulus is seen as *simply* as possible



- **Similarity**: similar things are grouped together



- **Proximity**: things that are *near* to each other are grouped together



- **Common fate**: things *moving in same* direction are grouped together



- **Common region**: elements in the *same region* tend to be grouped together 



- **Uniform connectedness**: *connected* visual properties are perceived as single unit

???

http://www.scholarpedia.org/article/Gestalt_principles

2 **Proximity** principle
3 **Common fate** principle
4 **Similarity** principle
5 **Continuity** principle

6 Closure principle
7 Good gestalt (form) principle

1 Figure-ground articulation
8 Past experience principle



---

# Perceptual Segregation

- Figure vs. (Back)Ground: determining what part of environment is the figure so that it "stands out" from the background
    - **figure** more “thinglike” &amp; more memorable
    - **figure** *in front of* ground
    - **ground** more uniform &amp; *extends behind* figure
    
- **Border Ownership**: Contour separating figure &amp; ground *belongs* to figure 

---

# Perceptual Segregation

![](fig_5_24.png)

???

Figure 5.24 A version of Rubin’s reversible face-vase figure.


---

# Perceptual Segregation

![](fig_5_25.png)

???

Figure 5.25 (a) When the vase is perceived as figure, it is seen in front of a homogeneous dark background. (b) When the faces are seen as figure, they are seen in front of a homogeneous light background.

---
class: inverse, center, middle

# Perceiving Scenes and Objects in Scenes

### Discuss research on semantic regularities in scenes.
### Discuss Helmholtz’s theory of unconscious inference, and Bayesian inference.
### Identify the rationale for and use of masking stimuli.


---

# Perceiving Scenes and Objects in Scenes
- Information within the image determines perception-grouping.
- Areas lower in the field of view are more likely to be perceived as a figure.


![](fig_5_27.png)

???

Figure 5.27 
- field (in the bottom half): figure. 
- sky (in the upper half): (back)ground


---

# Perceiving the Gist of a Scene
- Another Gestalt principle: figures are more likely to be perceived on the convex side of borders.



&lt;img src="ch5_files/figure-html/unnamed-chunk-1-1.png" width="933" /&gt;

---

# Perceiving the Gist of a Scene
.pull-left[
- Built-in principles can override experience.
    - Segregation of figure from ground
]
.pull-right[

![](fig_5_29.png)
]

???

Figure 5.29(a) W on top of M. (b) When combined, a new pattern emerges, overriding the meaningful letters. 




---

# Perceiving the Gist of a Scene
- A scene contains:
    - Background elements
    - Objects organized in meaningful ways with each other and the background
- Difference between objects and scenes
    - A scene is acted within.
    - An object is acted upon.



---

# Perceiving the Gist of a Scene

Global image features: 
- Color
- Degree of:
   - naturalness
   - openness
   - roughness
   - expansion 
  
Scene features are &lt;/br&gt; holistic and &lt;/br&gt;perceived rapidly.


.footnote.font60[
Boucart, M., Moroni, C., Thibaut, M., Szaffarczyk, S., &amp; Greene, M. (2013). Scene categorization at large visual eccentricities. Vision Research, 86, 35-42.
]


![:positionImage 18%, 29%, 0deg, 600px](scene.jpg)



???

Figure 5.34 four types of scenes that have different global image properties. 



---

# .font60[Regularities in the Environment: Information for Perceiving]
.pull-left[
- Physical regularities: regularly occurring physical properties
    - **Oblique effect**: people perceive horizontals and vertical more easily than other orientations.
    - **Uniform connectedness**: objects are defined by areas of the same color or texture.
]
.pull-right[
![](fig_5_35.png)
]

???

Figure 5.35 In these two scenes from nature, horizontal and vertical orientations are more common than oblique orientations. 
- These scenes are special examples, picked because the large proportion of verticals. 
- However, randomly selected photos of natural scenes also contain more horizontal and vertical orientations than oblique orientations. 
- This also occurs for human-made buildings and objects


---

# .font60[Regularities in the Environment: Information for Perceiving]
- **Physical regularities**: regularly occurring physical properties
    - Homogenous colors and nearby objects have different colors.
    - **Light-from-above** heuristic: light in natural environment comes from above us.

![](Light-from-above.jpg)

???

Figure 12.4 Effect of the light-from-above prior on perception using ambiguous images. The left and right images show footprints in the sand. In the left image the light illuminating the scene is actually coming from above, and the footprint is correctly seen as an indentation. In the right image, which is the left image presented upside down, the light is coming from below. Employing the light-from-above prior in this situation causes the footprint to be seen as embossed or raised from the surface. 

---

# .font60[Regularities in the Environment: Information for Perceiving]

.pull-left[
- Palmer experiment
    - Observers saw a context scene flashed briefly, followed by a target picture.
    - Results showed that:
- Targets congruent with the context were identified 80% of the time. 
- Targets that were incongruent were only identified 40% of the time.
]
.pull-right[

![](fig_5_37.png)
]

???

Figure 5.37 Stimuli used in Palmer’s (1975) experiment. The scene at the left is presented first, and the observer is then asked to identify one of the objects on the right. 


---

# .font60[Regularities in the Environment: Information for Perceiving]

![](fig_5_38.png)

???

Figure 5.38 “Multiple personalities of a blob.” 
- interpretation of identity of the “blob” inside circles
- depends on context 

---

# Role of Inference in Perception

.pull-left[

- Theory of unconscious inference
    - Created by Helmholtz (1866/1911) to explain why stimuli can be interpreted in more than one way
    - Likelihood principle: objects are perceived based on what is most likely to have caused the pattern
- Modern researchers use Bayesian inference that take probabilities into account.

]

.pull-right[

![](fig_5_39.png)
]

???

Figure 5.39 The display in (a) is usually interpreted as being (b) a blue rectangle in front of a red rectangle. It could, however, be (c) a blue rectangle and an appropriately positioned six-sided red figure.

---

# Predictive Processing and &amp; Perceptual Inference

![:positionImage 20%, 5%, 0deg, 200px](PP_models.png)
![:positionImage 12%, 40%, 0deg, 700px](PE-LFB.jpg)

.foot[
- Hutchinson, J. B., &amp; Barrett, L. F. (2019). The power of predictions: An emerging paradigm for psychological research. Current Directions in Psychological Science, 0963721419831992.

- Keller, G. B., &amp; Mrsic-Flogel, T. D. (2018). Predictive processing: a canonical cortical computation. Neuron, 100(2), 424-435.
]

---

# Role of Inference in Perception


![](fig_5_40.png)

???

Figure 5.40 These graphs present hypothetical probabilities, to illustrate the principle behind Bayesian inference. (a) Maria’s beliefs about the relative frequency of having a cold, lung disease, and heartburn. These beliefs are her priors. (b) Further data indicate that colds and lung disease are associated with coughing, but heartburn is not. These data contribute to the likelihood. (c) Taking the priors and likelihood together results in the conclusion that Charles’s cough is probably due to a cold.


---

# .font80[Connecting Neural Activity and Object Perception]

.pull-left[
- Brain responses to perceiving faces and places
    - Binocular rivalry
    - Tong and colleagues (1998) research
- Demonstrated that changes in perception and changes in brain activity mirrored each other
]

.pull-right[
![](fig_5_41.png)
]

???

Figure 5.41 Observers in Tong et al.’s (1998) experiment viewed the overlapping red house and green face through red–green glasses
- so the house image was presented to the right eye and the face image to the left eye. 
- Because of binocular rivalry, the observers’ perception alternated back and forth between the face and the house. 
- When the observers perceived the house, activity occurred in the parahippocampal place area (PPA) in the left and right hemispheres (red ellipses). 
- When observers perceived the face, activity occurred in the fusiform face area (FFA) in the left hemisphere (green ellipse). 


---

# .font70[Spotlight on the Parahippocampal Place Area]
.pull-left[
- When Tong's subjects perceived the house, parahippocampal area (PPA) became active
- Spatial layout hypothesis
- Are scenes or places necessary for activation of PPA?
    - Space defining vs. space ambiguous
]
.pull-right[
![](Schwartz_Sensation_2E_Figure 5.29.jpg)
]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="libs/myassets/remark-js/macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
