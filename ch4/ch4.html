<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Cortical Organization</title>
    <meta charset="utf-8" />
    <meta name="author" content="Sensory Processes – EXP3104" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link rel="stylesheet" href="libs/myassets/remark-css/hygge.css" type="text/css" />
    <link rel="stylesheet" href="https://afeld.github.io/emoji-css/emoji.css" type="text/css" />
    <link rel="stylesheet" href="libs/myassets/remark-css/header-footer.css" type="text/css" />
    <link rel="stylesheet" href="libs/myassets/remark-css/griddage.css" type="text/css" />
    <link rel="stylesheet" href="libs/myassets/remark-css/grid-some.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Cortical Organization
## Chapter 4
### Sensory Processes – EXP3104

---

class: inverse, center, middle




# Spatial Organization in the Visual Cortex
## Describe cortical magnification and why it occurs.
## Discuss properties of different types of columns in the visual cortex, and how this relates to how an object is represented in the cortex.

---
class: inverse, center, middle

# First, A Mathematics Joke...

---
class: clear, center, middle

&gt; "Topologists cannot tell the difference between a coffee cup and a donut."

![](Mug_and_Torus_morph.gif)

---

# Topology 101 

Topological Maps are more concerned about **relative**  than *absolute* positions.


![:positionImage 20%, 1%, 0deg,450px](nyc_subway_topological_map.png)

![:positionImage 20%, 53%, 0deg, 420px](nyc_geographical.jpg)




---
class: clear, inverse, center, middle


![:positionImage 30%, 30%, 0deg, 350px](map-4.jpg)


![:positionImage 55%, 1%, 0deg, 350px](map-1.jpg)

![:positionImage 55%, 60%, 0deg, 350px](map-9.jpg)

![:positionImage 1%, 60%, 0deg, 350px](map-3.jpg)



![:positionImage 1%, 1%, 0deg, 375px](Boston_crop.jpg)



---
class: inverse, center, middle


# Macroscopic Organization Of Information In Cortex



---

# Somatosensory Topology

- **Somatosensory Cortex** is proportional to information represented. (Number of neurons) 

![:positionImage 10%, 0%, 0deg, 900px](SI_Somatotopic_Maps_Main_fig1.jpg)
![:positionImage 53%, 20%, 0deg, 500px](humunculus_crop.jpg)



---

# Somatosensory Sub-zones in Cortex
### Cortical map topology corresponds to surface of facial subsection for each whisker.

.img-w50[
![](barrel_dev.jpg)
]


---

# .font60[Auditory Topology: Tonotopic Map of Basilar Membrane]

.pull-left[### .font50[**Cochlea**: tonotopic resonance along linear surface.]]
.pull-right[### .font50[**Auditory Cortex**: tonotopic map of cochlea surface.]]

![:positionImage 65%, 3%, 0deg, 80%](Piano_to_F.jpg)
![:positionImage 25%, 0%, 0deg, 450px](cochlea.jpg)
![:positionImage 25%, 50%, 0deg, 500px](cat_aud.jpg)






---

# .font70[The Neural Map on the Striate Cortex (Area V1)]
- Electronic map on V1
    - **Retinotopic map** is an electron map of the retina on the cortex.
    - **Cortical magnification** – a small area of the fovea is represented by a large area on the visual cortex

.pull-left[

![](fig_4_1.png)
]
.pull-right[
![](fig_4_2.png)
]

???

Figure 4.1 A person looking at a tree, showing how points A, B, C, and D are imaged on the retina and where these retinal activations cause activity in the brain. Although the distances between A and B and between C and D are about the same on the retina, the distance between A and B is much greater on the cortex. This is an example of cortical magnification, in which more space is devoted to areas of the retina near the fovea


Figure 4.2 The magnification factor in the visual system. The small area of the fovea is represented by a large area on the visual cortex


---
# .font70[The Neural Map on the Striate Cortex (Area V1)]

.pull-left[### .font70[**Positron emission tomography** (PET)]
- Harmless radioactive tracer injection.
- Tracer moves through bloodstream.
- Measure radioactivity in blood flow.
- Changes in blood flow indicates changes in brain activity.
]

.pull-right[
### **PET: subtraction method**
Brain activity is determined by:
- Measuring activity in control state
- Measuring activity in stimulation state
- Subtracting control activity from stimulation activity
]

![:positionImage 55%, 5%, 0deg, 350px](PET-schema.png)
![:positionImage 55%, 55%, 0deg, 350px](Effect-of-background-subtraction-on-86-Y-PET-imaging-PET-imaging-of-86-Y-DOTATOC-with.png)


---

# .font70[The Neural Map on the Striate Cortex (Area V1)]

- Functional magnetic resonance imaging (fMRI)
    - Hemoglobin carries oxygen and contains a ferrous molecule that is magnetic.
    - Brain activity takes up oxygen, which makes the hemoglobin more magnetic.
    - fMRI determines activity of areas of the brain by detecting changes in magnetic response of hemoglobin.
- Subtraction technique is used as in PET.


![](fig_4_3.png)

???

Figure 4.3 (a) A person in a brain scanner. (b) fMRI record. Each small square represents a voxel, and the colors indicate whether brain activity increased or decreased in the each voxel. Red and yellow indicate increases in brain activity; blue and green indicate decreases. 

---

# .font70[The Neural Map on the Striate Cortex (Area V1)]

.pull-left[
![](fig_4_4a.png)
]

.pull-right[
![](fig_4_4b.png)
]

???

Figure 4.4 (a) Red and blue areas show the extent of stimuli that were presented while a person was in an fMRI scanner. (b) Red and blue indicate areas of the brain activated by the stimulation in (a). 




---

![](calcarine.jpg)

---

![:image 90%](slide_23.jpg)


---

# .font70[The Neural Map on the Striate Cortex (Area V1)]

- Cortical magnification factor
    - Fovea has more cortical space than expected.


![](fig_4_5.png)

???

Figure 4.5 Demonstration of the magnification factor. A person looks at the red spot on the text on the left. The area of brain activated by each letter of the text is shown on the right. The arrows point to the letter a in the text on the left, and the area in the brain activated by the a on the right.

---
class: inverse, center
background-image: url(micro-meso-macro.jpg)
background-size: 95%

# .font70[Mesoscopic Cortical Column Organization]


???

Dumoulin, S. O., Fracasso, A., van der Zwaag, W., Siero, J. C., &amp; Petridou, N. (2018). Ultra-high field MRI: Advancing systems neuroscience towards mesoscopic human brain function. Neuroimage, 168, 345-357.

---

# The Cortex is Organized in Columns

.pull-left[
Visual cortex shows:
- **Location columns**
  - Receptive fields at the same location on the retina are within a column.
- **Orientation columns**
  - Neurons within columns fire maximally to the same orientation of stimuli.
  - Adjacent columns change preference in an orderly fashion.
  - One millimeter across the cortex represents entire range of orientation.
]


.pull-right[
![](fig_4_6.png)
]

???

Figure 4.6 Location column. When an electrode penetrates the cortex perpendicularly, the receptive fields of the neurons encountered along this track overlap. The receptive field recorded at each numbered position along the electrode track (a) is indicated by a correspondingly numbered square (b).


---

# The Cortex is Organized in Columns

![](orientation_column.png)


???

Figure 4.7 Orientation columns. All of the cortical neurons encountered along track A respond best to horizontal bars (indicated by the red lines cutting across the electrode track). All of the neurons along track B respond best to bars oriented at 45 degrees.


---

# The Cortex is Organized in Columns 

![](fig_4_9.png)


???

Figure 4.9 A location column that contains the full range of orientation columns. A column such as this, which Hubel and Wiesel called a hypercolumn, receives information about all possible orientations that fall within a small area of the retina

---

# The Cortex is Organized in Columns  
.pull-left[
- **Ocular dominance column**
    - Neurons in the cortex respond preferentially to one eye.

- **Hypercolumn**
   - Each contains the full set of characteristics for a single location in the retina &amp; visual field 
]
.pull-right[
### A "hypercolumn" has full range of orientations &amp; 1 ipsilateral &amp; 1 contralateral

![](Hypercolumn.png)
]

---

# .font60[How Do Orientation-Sensitive Neurons Respond to a Scene?]
- **Tiling** – columns working together to cover the entire visual field


![](fig_4_10.png)


???

Figure 4.10 (a) A scene from the Pennsylvania woods. (b) Focusing in on part of a tree trunk. A, B, and C represent the parts of the tree trunk that fall on receptive fields in three areas of the retina


---

# .font70[How Do Orientation-Sensitive Neurons Respond?]

![:positionImage 12%, 5%, 0deg, 350px](fig_4_11.png)
--

![:positionImage 15%, 55%, 0deg, 350px](fig_3_37a.png)
![:positionImage 55%, 15%, 0deg, 350px](fig_3_37d.png)

???

Figure 4.11 (a) Receptive fields A, B, and C, located on the retina, for the three sections of the tree trunk from Figure 4.10b. The neurons associated with each of these receptive fields are in different location columns. (b) Three location columns in the cortex. Neurons that fire to the tree trunk’s orientation are within the orange areas of the location column


---

# .font70[How Do Orientation-Sensitive Neurons Respond?]

![](fig_4_12.png)


???

Figure 4.12 The yellow circles and ellipses superimposed on the forest scene each represent an area that sends information to one location column in the cortex. There are actually many more columns than shown here, and they overlap, so that they cover the entire scene. The way these location columns cover the entire scene is called tiling. 

---
class: inverse, center, middle

# Pathways for What, Where, and How

## Identify the logic of lesions (ablations) in studying the brain.
## Describe the research by Ungerleider and Mishkin on the “what” and “where” pathways, and Milner and Goodale on the “how” pathway.
## Explain the logic involved in establishing a double dissociation and provide an example of one.


---

# .font80[Streams for Information About What and Where]
- Lesioning or Ablation Experiments 
    - First, an animal is trained to indicate perceptual capacities.
    - Second, a specific part of the brain is removed or destroyed.
    - Third, the animal is retrained to determine which perceptual abilities remain.
    - The results reveal which portions of the brain are responsible for specific behaviors.


---

# .font80[Streams for Information About What and Where]
.pull-left[
Ungerleider and Mishkin experiment
- **Object discrimination problem**
   - A monkey is shown an object, a "rectangle block".
   - Then it is presented with a two choice task.
   - A reward is given for detecting the rectanglular target object
- **Landmark discrimination problem**
- The monkey is trained to pick the food well next to a cylinder.
]
.pull-right[
![](fig_4_13.png)
]

???

Figure 4.13 The two types of discrimination tasks used by Ungerleider and Mishkin. (a) Object discrimination: Pick the correct shape. Lesioning the temporal lobe (shaded area) makes this task difficult. (b) Landmark discrimination: Pick the food well closer to the cylinder. Lesioning the parietal lobe makes this task difficult. 

---

# .font80[Streams for Information About What and Where]
.pull-left[
- Ungerleider and Mishkin: using ablation, part of the parietal lobe was removed from half the monkeys and part of the temporal lobe was removed from the other half
    - Retesting the monkeys showed that:
- Removal of temporal lobe tissue resulted in problems with the landmark discrimination task: **what pathway**
- Removal of parietal lobe tissue resulted in problems with the object discrimination task: **where pathway**
]
.pull-right[
### Task Performance

| |**2-Choice** Task |**Landmark** Task |
|:---|:---:|:---:|
|**Parietal** Ablation |  **++**  |  .red.font100[**x**]  |
|**Temporal** Ablation |  .red.font100[**x**]  | **++**  |
]


---

# .font80[Streams for Information About What and Where]


![:positionImage 15%, 5%, 0deg, 800px](fig_4_14.png)
  


???

Figure 4.14 The monkey cortex, showing the what, or ventral, pathway from the occipital lobe to the temporal lobe, and the where, or dorsal, pathway from the occipital lobe to the parietal lobe. The where pathway is also called the How pathway. 



---

# .font80[Streams for Information About What and Where]

![](fig_4_15.png)


???

Figure 4.15 Dorsal refers to the back surface of an organism. In upright standing animals such as humans, dorsal refers to the back of the body and to the top of the head, as indicated by the arrows and the curved dashed line. Ventral is the opposite of dorsal. 

---

# .font80[Streams for Information About What and How]
- Where pathway may actually be a **“how”** pathway, or an action pathway
    - **Dorsal stream** towards Parietal lobe shows function for both location and for action.
    - Evidence from neuropsychology 
- **Double dissociations**: two functions that involve different mechanisms and operate independently

---

# .font80[Streams for Information About What and How]
- Behavior of patient D.F.
    - Damage to ventral pathway due to gas leak
    - Not able to match orientation of card with slot
    - But able to match orientation if she was placing card in a slot
- Other patients show opposite effects.
    - Evidence shows double dissociation between the ventral and dorsal pathways.
.img-w70[
![](fig_4_t1.png)
]

---

# .font80[Streams for Information About What and How]

.pull-left[
![](DF_posting.JPG)
]

--

.pull-right[
![](fig_4_16.png)
]
???

Figure 4.16 Performance of D.F. and a person without brain damage on two tasks: (a) judging the orientation of a slot and (b) placing a card through the slot. Vertical lines indicate perfect matching performance. 




---
class: inverse, center, middle

# .font70[Modularity vs Distributed Representations]

## .font70[Discuss research on modularity, including locations of specialized cells and specific stimuli, in both monkeys and humans.]



---

# Modularity

.pull-left[
- **Module**: a brain structure that processes information about specific stimuli
    - Rolls measured the response neurons in the *inferotemporal* (IT) cortex in monkeys 
- Responds best to faces with little response to non-face stimuli
    - Temporal lobe damage in humans results in *prosopagnosia*.
]
.pull-right[
![](fig_4_18.png)
]

???

Figure 4.18 Size of response of a neuron in the monkey’s IT cortex that responds to face stimuli but not to non-face stimuli. These ventral stream neurons in Inferotemporal cortex are very specific even though human faces are not very similar to monkey faces.

???
http://scholarpedia.org/article/Modular_models_of_brain_function
https://en.m.wikipedia.org/wiki/Visual_modularity
http://scholarpedia.org/article/Neural_net_language_models#Distributed_Representations

---

# Modularity

![](fig_4_19.png)

???

Figure 4.19 Results of the Tsao et al. (2006) experiment in which activity of neurons in the monkey’s temporal lobe was recorded in response to faces, other objects, and a scrambled stimulus. 


---
# .font60[Representation of Complex Sets of Features in Visual Pathways]

![](fncom-08-00135-g001.jpg)


---

# .font70[Areas for Faces, Places, and Bodies in the Human Brain]

.pull-left[
Evidence from humans using fMRI and the subtraction technique show that:
- **Fusiform face area** (FFA) responds best to faces 
- **Parahippocampal place area** (PPA) responds best to spatial layout
- **Extrastriate body area** (EBA) responds best to pictures of full bodies and body parts 
]
.pull-right[

![](fig_4_20.png)
]

???

- PPA (Parahippocampal Place Area): places NOT other
- EBA (Extrastriate body area): bodies NOT other

---

# Distributed Representation

- Distributed representation
    - A stimulus causes neural activity in a number of different areas of the brain.
    - Activity is distributed across the brain.


---

# .font70[Distributed Representation: Multidimensional Stimuli]

.pull-left[
- We respond to other aspects of faces.
    - Emotional aspects
    - Where someone is looking
    - How parts of the face move
    - How attractive a face is
    - Whether the face is familiar
- Also multi-dimensions of pain

![](fig_4_24a.png)
]

--

.pull-right[
![](fig_4_24b.png)
]

???

Figure 4.24 
- (a) Areas activated by different aspects of faces. (dashed line amygdala inside the brain) 
- (b) Areas involved in pain perception. Each area serves a different aspect of pain perception. 


---

# .font70[Distributed Representation: Multidimensional Stimuli]

![](fig_4_t2.png)



---

# Where Perception Meets Memory
- **Medial temporal lobe** (MTL) structures are extremely important in memory.
    - The case of H.M.
    - The **hippocampus**

![](hippocampus.png)

---

# Where Perception Meets Memory

![](fig_4_25.png)

???

Figure 4.25 (a) Location of the hippocampus and some of the other structures that were studied by Quiroga and coworkers (2005)

Halle Berry

---

# The Mind-Body Problem 

.img-w50[
![](fig_4_27.png)
]

???

Figure 4.27
- (a) most of the physiological experiments in book
    - correlations between physiological responding (nerve firing) &amp; experience perceiving “Susan’s face” or “red.” 
- (b) solving mind–body problem: go beyond corr. 
    - to determine how ion flow or nerve firing 
    - **causes the experiences** of “Susan’s face” or the color “red.” 


---

# The Mind-Body Problem 

![:positionImage 14%, 5%, 0deg, 800px](micro-meso-macro.jpg)
--
![:positionImage 13%, 30%, 0deg, 40px](images/rt-arrow.png)
![:positionImage 13%, 63%, 0deg, 40px](images/rt-arrow.png)

--

![:positionImage 65%, 1%, 0deg, 230px](smiling_lens.jpg)

---

# The Mind-Body Problem 

![:positionImage 14%, 5%, 0deg, 800px](micro-meso-macro.jpg)



![:positionImage 65%, 1%, 0deg, 230px](smiling_lens.jpg)


![:positionImage 13%, 63%, 0deg, 40px](images/rt-arrow.png)
![:positionImage 13%, 30%, 0deg, 40px](images/rt-arrow.png)

![:positionImage 17%, 28%, 0deg, 40px](images/lt-arrow.png)

![:positionImage 17%, 61%, 0deg, 40px](images/lt-arrow.png)


![:positionImage 65%, 32%, 0deg, 160px](cade-face.png)

--


![:positionImage 56.79%, 25%, 0deg, 500px](images/long-rt_arrow.png)

![:positionImage 55%, 10%, 180deg, 500px](images/long-lt_arrow.png)

--

![:positionImage 65%, 55%, 0deg, 400px](train.gif)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="libs/myassets/remark-js/macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
